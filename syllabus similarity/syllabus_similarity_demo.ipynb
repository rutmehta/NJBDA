{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllabus Similarity Notebook\n",
    "This notebook parses two syllabi (PDF or DOCX), sections them, computes embeddings, and outputs a similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import docx\n",
    "import spacy\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use BERT-based all-mpnet-base-v2 for best semantic similarity\n",
    "MODEL_NAME = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "nlp = spacy.blank(\"en\")  # Or use a full model for more advanced parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        return \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.text for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eaa5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import difflib\n",
    "\n",
    "# Canonical section titles (expand as needed)\n",
    "SECTION_TITLES = [\n",
    "    \"Course Description\", \"Learning Outcomes\", \"Objectives\", \"Prerequisites\",\n",
    "    \"Textbook\", \"Required Materials\", \"Grading\", \"Schedule\", \"Policies\",\n",
    "    \"Attendance\", \"Assignments\", \"Instructor\", \"Contact\", \"Office Hours\"\n",
    "]\n",
    "\n",
    "def find_closest_section(line, section_titles, cutoff=0.75):\n",
    "    \"\"\"Return the closest matching section title or None.\"\"\"\n",
    "    matches = difflib.get_close_matches(line.strip().lower(), [s.lower() for s in section_titles], n=1, cutoff=cutoff)\n",
    "    if matches:\n",
    "        # Return canonical capitalization\n",
    "        idx = [s.lower() for s in section_titles].index(matches[0])\n",
    "        return section_titles[idx]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88429774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_syllabus_text(text):\n",
    "    \"\"\"Parse syllabus text into sections using fuzzy header matching.\"\"\"\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    buffer = []\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        # Try to match a section header\n",
    "        match = find_closest_section(line, SECTION_TITLES)\n",
    "        if match:\n",
    "            if current_section and buffer:\n",
    "                sections[current_section] = \"\\n\".join(buffer).strip()\n",
    "                buffer = []\n",
    "            current_section = match\n",
    "        elif current_section:\n",
    "            buffer.append(line)\n",
    "    if current_section and buffer:\n",
    "        sections[current_section] = \"\\n\".join(buffer).strip()\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cdc99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_syllabus(file_path):\n",
    "    # Extract and clean text\n",
    "    if file_path.lower().endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.lower().endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    # Section the syllabus\n",
    "    sections = section_syllabus_text(text)\n",
    "    return sections\n",
    "\n",
    "def syllabus_to_json(file_path):\n",
    "    # Parse and return as JSON/dict\n",
    "    return parse_syllabus(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c99a5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_section(text):\n",
    "    return model.encode(text or \"\", show_progress_bar=False)\n",
    "\n",
    "def compute_section_similarities(s1, s2, section_titles=SECTION_TITLES):\n",
    "    sims = []\n",
    "    for section in section_titles:\n",
    "        t1 = s1.get(section, \"\")\n",
    "        t2 = s2.get(section, \"\")\n",
    "        if t1.strip() and t2.strip():\n",
    "            emb1 = embed_section(t1)\n",
    "            emb2 = embed_section(t2)\n",
    "            sim = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        else:\n",
    "            sim = 0.0\n",
    "        sims.append(sim)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DataFrame with columns: pdf1, pdf2, label\n",
    "df = pd.read_csv(\"syllabus_pairs.csv\")\n",
    "results = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    syl1 = syllabus_to_json(row['pdf1'])\n",
    "    syl2 = syllabus_to_json(row['pdf2'])\n",
    "    sim = compute_similarity(syl1, syl2)\n",
    "    results.append({\"sim\": sim, \"label\": row['label']})\n",
    "\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb60c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save parsed syllabi as JSON for schema consistency check\n",
    "for file in Path(\"syllabi\").glob(\"*\"):\n",
    "    parsed = syllabus_to_json(str(file))\n",
    "    with open(f\"{file}.json\", \"w\") as f:\n",
    "        json.dump(parsed, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DataFrame with columns: pdf1, pdf2, label\n",
    "df = pd.read_csv(\"syllabus_pairs.csv\")\n",
    "X = []\n",
    "y = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    s1 = parse_syllabus(row['pdf1'])\n",
    "    s2 = parse_syllabus(row['pdf2'])\n",
    "    feats = compute_section_similarities(s1, s2)\n",
    "    X.append(feats)\n",
    "    y.append(row['label'])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(fit_intercept=False, solver='liblinear')\n",
    "clf.fit(X, y)\n",
    "print(\"Learned section weights:\")\n",
    "for section, weight in zip(SECTION_TITLES, clf.coef_[0]):\n",
    "    print(f\"{section}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "map_score = average_precision_score(df_results['label'], df_results['sim'])\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Syllabus Parsing and Sectioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_TITLES = [\n",
    "    'Course Description', 'Learning Outcomes', 'Objectives', 'Prerequisites',\n",
    "    'Textbook', 'Required Materials', 'Grading', 'Schedule', 'Policies', 'Attendance',\n",
    "    'Assignments', 'Instructor', 'Contact', 'Office Hours'\n",
    "]\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        return '\\n'.join(page.extract_text() or '' for page in pdf.pages)\n",
    "\n",
    "def extract_text_from_docx(docx_path: str) -> str:\n",
    "    doc = docx.Document(docx_path)\n",
    "    return '\\n'.join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def section_syllabus_text(text: str) -> Dict[str, str]:\n",
    "    sections = {}\n",
    "    current_section = None\n",
    "    buffer = []\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        line_strip = line.strip()\n",
    "        matched = False\n",
    "        for title in SECTION_TITLES:\n",
    "            if re.fullmatch(title, line_strip, re.IGNORECASE):\n",
    "                if current_section and buffer:\n",
    "                    sections[current_section] = '\\n'.join(buffer).strip()\n",
    "                    buffer = []\n",
    "                current_section = title\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched and current_section:\n",
    "            buffer.append(line)\n",
    "    if current_section and buffer:\n",
    "        sections[current_section] = '\\n'.join(buffer).strip()\n",
    "    return sections\n",
    "\n",
    "def parse_syllabus(file_path: str) -> Dict[str, str]:\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.lower().endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError('Unsupported file type')\n",
    "    return section_syllabus_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdec50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_found_sections(syllabus_dict, label):\n",
    "    print(f\"Sections found in {label}:\")\n",
    "    for section, content in syllabus_dict.items():\n",
    "        print(f\"  {section}: {len(content.split())} words\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2341ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text, model):\n",
    "    return model.encode(text or '', show_progress_bar=False)\n",
    "\n",
    "def fallback_document_similarity(s1_text, s2_text, model):\n",
    "    emb1 = embed_text(s1_text, model)\n",
    "    emb2 = embed_text(s2_text, model)\n",
    "    return cosine_similarity([emb1], [emb2])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Syllabus Similarity Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "SECTION_WEIGHTS = {\n",
    "    'Course Description': 2.0,\n",
    "    'Learning Outcomes': 3.0,\n",
    "    'Objectives': 2.0,\n",
    "    'Prerequisites': 1.0,\n",
    "    'Grading': 0.5,\n",
    "    'Schedule': 1.0,\n",
    "}\n",
    "ALL_SECTIONS = list(SECTION_WEIGHTS.keys())\n",
    "\n",
    "def embed_section(section_text: str) -> np.ndarray:\n",
    "    return model.encode(section_text or '', show_progress_bar=False)\n",
    "\n",
    "def compare_syllabi(s1: Dict[str, str], s2: Dict[str, str]) -> Tuple[float, Dict[str, float]]:\n",
    "    similarities = {}\n",
    "    weighted_sum = 0.0\n",
    "    total_weight = 0.0\n",
    "    for section in ALL_SECTIONS:\n",
    "        t1 = s1.get(section, '')\n",
    "        t2 = s2.get(section, '')\n",
    "        if t1.strip() and t2.strip():\n",
    "            emb1 = embed_section(t1)\n",
    "            emb2 = embed_section(t2)\n",
    "            sim = cosine_similarity([emb1], [emb2])[0][0]\n",
    "        else:\n",
    "            sim = 0.0\n",
    "        similarities[section] = sim\n",
    "        weighted_sum += sim * SECTION_WEIGHTS[section]\n",
    "        total_weight += SECTION_WEIGHTS[section]\n",
    "    overall_score = weighted_sum / total_weight if total_weight else 0.0\n",
    "    return overall_score, similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demo: Compare Two Syllabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sections found in Syllabus 1:\n",
      "  Course Description: 58 words\n",
      "  Textbook: 615 words\n",
      "\n",
      "Sections found in Syllabus 2:\n",
      "  Course Description: 66 words\n",
      "  Textbook: 1135 words\n",
      "\n",
      "Overall Section-Based Similarity Score: 0.069\n",
      "Section Similarities:\n",
      "  Course Description: 0.326\n",
      "  Learning Outcomes: 0.000\n",
      "  Objectives: 0.000\n",
      "  Prerequisites: 0.000\n",
      "  Grading: 0.000\n",
      "  Schedule: 0.000\n",
      "\n",
      "Section-based similarity is very low. Falling back to whole-document similarity...\n",
      "Whole-Document Similarity Score: 0.536\n"
     ]
    }
   ],
   "source": [
    "# Example usage: replace with your file paths\n",
    "syllabus1_path = '/Users/rutmehta/Developer/NJBDA/syllabi/AERG200_syllabus.docx'  # or .docx\n",
    "syllabus2_path = '/Users/rutmehta/Developer/NJBDA/syllabi/AERG101_syllabus.docx'  # or .docx\n",
    "\n",
    "s1 = parse_syllabus(syllabus1_path)\n",
    "s2 = parse_syllabus(syllabus2_path)\n",
    "\n",
    "print_found_sections(s1, \"Syllabus 1\")\n",
    "print_found_sections(s2, \"Syllabus 2\")\n",
    "\n",
    "overall_score, section_scores = compare_syllabi(s1, s2)\n",
    "print(f'Overall Section-Based Similarity Score: {overall_score:.3f}')\n",
    "print('Section Similarities:')\n",
    "for section, score in section_scores.items():\n",
    "    print(f'  {section}: {score:.3f}')\n",
    "\n",
    "# Fallback: If section-based similarity is too low, use whole-document similarity\n",
    "if overall_score < 0.1:\n",
    "    print(\"\\nSection-based similarity is very low. Falling back to whole-document similarity...\")\n",
    "    # Re-extract raw text for both syllabi\n",
    "    s1_text = extract_text_from_pdf(syllabus1_path) if syllabus1_path.lower().endswith('.pdf') else extract_text_from_docx(syllabus1_path)\n",
    "    s2_text = extract_text_from_pdf(syllabus2_path) if syllabus2_path.lower().endswith('.pdf') else extract_text_from_docx(syllabus2_path)\n",
    "    doc_score = fallback_document_similarity(s1_text, s2_text, model)\n",
    "    print(f'Whole-Document Similarity Score: {doc_score:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
